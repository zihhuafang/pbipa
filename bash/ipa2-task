#!/bin/bash

THISDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"

function helper_load_config {
    local config_sh_fn="$1"
    test ! -z ${config_sh_fn} && test -f ${config_sh_fn} && source ${config_sh_fn}
}

function which {
    unset -f which
    which "$1"
}

function generate_config_ccs {
    # Inputs:
    #   params_existing_db_prefix
    #   params_genome_size
    #   params_coverage
    #   params_block_size
    #   params_ovl_opt
    #   params_ovl_flank_grace
    #   params_ovl_min_idt
    #   params_ovl_min_len
    #   params_ovl_filter_opt
    # Output:
    #   config.sh

    # First, write out the workflow options.
    echo "existing_db_prefix=${params_existing_db_prefix}" > config.sh
    echo "genome_size=${params_genome_size}" >> config.sh
    echo "coverage=${params_coverage}" >> config.sh
    echo "block_size=${params_block_size}" >> config.sh
    echo "seqdb_opt='${params_seqdb_opt}'" >> config.sh
    echo "seeddb_opt='${params_seeddb_opt}'" >> config.sh
    echo "ovl_opt_erc='${params_ovl_opt}'" >> config.sh
    echo "ovl_flank_grace=${params_ovl_flank_grace}" >> config.sh
    echo "ovl_min_idt=${params_ovl_min_idt}" >> config.sh
    echo "ovl_min_len=${params_ovl_min_len}" >> config.sh
    echo "ovl_filter_opt='${params_ovl_filter_opt}'" >> config.sh
    echo "use_seq_ids=${params_use_seq_ids}" >> config.sh
}

function build_db {
    # Inputs:
    #   input_reads_fn
    # Params:
    #   params_db_prefix
    #   params_config_sh_fn
    # Outputs:
    #   {db_prefix}.rdb
    #   input.fofn

    helper_load_config ${params_config_sh_fn}

    # Create a FOFN of input sequences, even if the input is a
    # plain single sequence file.
    local input_reads_ext=${input_reads_fn##*.}
    if [[ \"${input_reads_ext}\" -eq "fofn" ]]; then
        cp ${input_reads_fn} input.fofn
    else
        echo "${input_reads_fn}" > input.fofn
    fi

    # If the user specified a DB prefix, just symlink it.
    if [[ -z "${existing_db_prefix}" ]]; then
        # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.build_db.seqdb.memtime \
        pancake seqdb --compression 0 --block-size ${block_size} ${seqdb_opt} ${params_db_prefix} ${input_reads_fn}

        # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.build_db.seeddb.memtime \
        /usr/bin/time pancake seeddb ${seeddb_opt} ${params_db_prefix}.seqdb ${params_db_prefix}
    else
        ln -sf ${existing_db_prefix}.seqdb ${params_db_prefix}.seqdb
        for fn in ${existing_db_prefix}.seqdb.*
        do
            ln -sf ${fn}
        done

        ln -sf ${existing_db_prefix}.seeddb ${params_db_prefix}.seeddb
        for fn in ${existing_db_prefix}.seeddb.*
        do
            ln -sf ${fn}
        done
    fi
}

function ovl_prepare {
    # Input:
    #   input_db
    # Output:
    #   *.txt in cwd
    #   ${output_blocks} (same info in 1 file)

    num_blocks=$(awk '/^B/{count++}END{print count}' "${input_db}")
    for ((block1=0;block1<num_blocks;block1++)); do
        echo $block1 > $block1.txt
        echo ${block1}
    done > ${output_blocks}

    if [[ ! -s ${output_blocks} ]]; then
        echo "0" > ${output_blocks}
    fi
}

function ovl_asym_run {
    helper_load_config ${params_config_sh_fn}
    local params_ovl_opt=${ovl_opt_erc}
    local params_ovlp_flank_grace=${ovl_flank_grace}

    # These are explicit inputs:
    #   params_block_id
    #   params_num_threads
    #   params_config_sh_fn
    #   params_db_prefix

    local local_db_prefix=$(dirname ${input_seqdb})/${params_db_prefix}
    local last_block=$((params_block_id + 1))

    local opt_use_seq_ids=""
    if [[ ${use_seq_ids} -eq 1 ]]; then
        opt_use_seq_ids="--write-ids"
    fi

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.ovl_asym_run.pancake.memtime \
    pancake ovl-hifi --num-threads ${params_num_threads} --skip-sym --write-rev ${opt_use_seq_ids} ${params_ovl_opt} --log-level=INFO ${local_db_prefix} ${local_db_prefix} ${params_block_id} ${params_block_id} 0 > ovl.m4

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.ovl_asym_run.sort.memtime \
    sort -k 1,1 ovl.m4 > ovl.sorted.m4
}

function ovl_asym_merge {
    helper_load_config ${params_config_sh_fn}
    # Explicit inputs:
    #   input_fofn
    # Explicit parameters:
    #   params_num_threads
    #   params_config_sh_fn

    cat ${input_fofn}
    while read fn; do
        ls -lH ${fn}
    done < ${input_fofn}

    # Merge sort.
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.ovl_asym_merge.mergesort.memtime \
    sort -k1,1 -m $(cat ${input_fofn} | xargs) > ovl.merged.m4
    echo ovl.merged.m4 > ovl.merged.fofn

    # Filter out any local alignments. Important for phasing.
    awk '{ if ($13 != "u") { print } }' ovl.merged.m4 > ovl.nonlocal.m4
}

function phasing_prepare {
    # Input:
    #   input_m4
    # Output:
    #   *.m4 in cwd
    #   ${output_blocks} (same info in 1 file)
    # Parameters:
    #   params_num_blocks

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.phasing_prepare.nighthawk_split.memtime \
    nighthawk split --nFiles ${params_num_blocks} chunk ${input_m4}
}

function phasing_run {
    # These are explicit inputs:
    #   input_fasta
    #   input_m4
    # Outputs:
    #   output_keep_m4
    #   output_scraps_m4
    # Parameters:
    #   params_num_threads

    helper_load_config ${params_config_sh_fn}

    local opt_use_seq_ids=""
    if [[ ${use_seq_ids} -eq 1 ]]; then
        opt_use_seq_ids="--alias"
    fi

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.phasing_run.nighthawk_phase.memtime \
    nighthawk phase ${opt_use_seq_ids} ${input_fasta} ${input_m4} ${output_scraps_m4} > ${output_keep_m4}
}

function phasing_merge {
    # These are explicit inputs:
    #   input_keep_fofn
    #   input_scraps_fofn
    # Outputs:
    #   output_m4
    # Parameters:
    #   params_num_threads

    cat ${input_keep_fofn} | xargs cat > all.keep.m4
    cat ${input_scraps_fofn} | xargs cat > all.scraps.m4

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.phasing_merge.nighthawk_symmetrical.memtime \
    nighthawk symmetrical all.scraps.m4 all.keep.m4  > ${output_m4}
}

function ovl_filter {
    # Explicit inputs:
    #   input_m4
    # Explicit outputs:
    #   output_m4_final
    #   output_m4_chimerfilt
    # Parameters:
    #   params_num_threads
    #   params_config_sh_fn

    helper_load_config ${params_config_sh_fn}

    echo ${input_m4} > ovl.fofn

    # Filter.
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.ovl_asym_merge.m4filt.memtime \
    falconc  m4filt-ipaRunner --n-proc ${params_num_threads} --ovls-fofn ovl.fofn --output-fn ${output_m4_chimerfilt} --keepIntermediates ${ovl_filter_opt} --filter-log m4-readfilt.log

    # Containment removal.
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.ovl_asym_merge.m4filtcontained.memtime \
    falconc m4filt-contained --min-idt ${ovl_min_idt} --min-len ${ovl_min_len} --in ${output_m4_chimerfilt} --out ${output_m4_final}
}

function assemble {
    set -o

    helper_load_config ${params_config_sh_fn}

    # These are explicit inputs:
    #   params_ctg_prefix
    #   params_config_sh_fn

    ln -sf ${input_m4} preads.m4
    ln -sf ${input_reads}
    ln -sf ${input_reads} preads4falcon.fasta

    preads4falcon_bn=$(basename ${input_reads})

    # Make ovlp_to_graph reproducible.
    export PYTHONHASHSEED=2147483647

    # Run the assembly.
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.assemble.ovlp_to_graph.memtime \
    python3 ${IPA2_WORKSPACE}/scripts/ovlp_to_graph.py --depth-cutoff 20000 --width-cutoff 30000 --length-cutoff 15000000 --ctg-prefix "${params_ctg_prefix}" --overlap-file preads.m4 >| fc_ovlp_to_graph.log

    local opt_use_seq_ids=""
    if [[ ${use_seq_ids} -eq 1 ]]; then
        opt_use_seq_ids="--seqdb-fn ${input_seqdb}"
    fi
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.assemble.graph_to_contig.memtime \
    python3 ${IPA2_WORKSPACE}/scripts/graph_to_contig.py ${opt_use_seq_ids} --preads-fasta-fn ${preads4falcon_bn} 2>&1 | tee fc_graph_to_contig.log

    # Implicit outputs: p_ctg.fasta, a_ctg_all.fasta, p_ctg_tiling_path, a_ctg_all_tiling_path

    if [[ -s p_ctg.fasta ]]; then
        ls -larth p_ctg.fasta
        pwd
        samtools faidx p_ctg.fasta  # for oric later
        (grep ">" p_ctg.fasta | grep "ctg_circular" | cut -d ' ' -f 1 | tr -d ">" > circular_contigs.csv) || touch circular_contigs.csv
        ### The following line crashed in one example, so I removed it:
        # falconc stats-assembly --fasta p_ctg.fasta >| p_ctg.fasta.stats
    else
        ls -larth
        touch circular_contigs.csv
        touch p_ctg.fasta.stats
    fi

    # Given a_ctg_all.fasta, write a_ctg.fasta:
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.assemble.dedup_a_tigs.memtime \
    # python3 -m falcon_kit.mains.dedup_a_tigs >| a_ctg.fasta
    touch a_ctg.fasta

    if [[ -s a_ctg.fasta ]]; then
        samtools faidx a_ctg.fasta
    fi

    # Given a_ctg.fasta and a_ctg_all_tiling_path, write a_ctg_tiling_path:
    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.assemble.dedup_a_tph.memtime \
    # python3 -m falcon_kit.mains.dedup_a_tp >| a_ctg_tiling_path
    touch a_ctg_tiling_path
}

function get_gfa {
    ### The following lines are commented out because they take plenty of time to run.
    # Collect all info needed to format the GFA-1 and GFA-2 representations of
    # the assembly graphs.
    time python3 -m falcon_kit.mains.collect_pread_gfa >| asm.gfa.json
#    time python3 -m falcon_kit.mains.collect_pread_gfa --write-reads >| asm.preads.gfa.json
    time python3 -m falcon_kit.mains.collect_pread_gfa --add-string-graph >| sg.gfa.json
#    time python3 -m falcon_kit.mains.collect_pread_gfa --add-string-graph --write-reads >| sg.preads.gfa.json
    time python3 -m falcon_kit.mains.collect_contig_gfa >| contig.gfa.json

    # Output the assembly pread graph.
    time python3 -m falcon_kit.mains.gen_gfa_v1 asm.gfa.json >| asm.gfa
#    time python3 -m falcon_kit.mains.gen_gfa_v1 asm.preads.gfa.json >| asm.preads.gfa
    time python3 -m falcon_kit.mains.gen_gfa_v2 asm.gfa.json >| asm.gfa2
    time python3 -m falcon_kit.mains.gen_bandage_csv asm.gfa.json >| asm.csv

    # Output the string graph.
    time python3 -m falcon_kit.mains.gen_gfa_v1 sg.gfa.json >| sg.gfa
#    time python3 -m falcon_kit.mains.gen_gfa_v1 sg.preads.gfa.json >| sg.preads.gfa
    time python3 -m falcon_kit.mains.gen_gfa_v2 sg.gfa.json >| sg.gfa2
    time python3 -m falcon_kit.mains.gen_bandage_csv sg.gfa.json >| sg.csv

    # Output the contig graph with associate contigs attached to each primary contig.
    time python3 -m falcon_kit.mains.gen_gfa_v2 contig.gfa.json >| contig.gfa2
}

function build_contig_db {
    # Inputs:
    #   input_p_ctg_fasta
    #   input_a_ctg_fasta
    # Params:
    #   params_db_prefix
    #   params_config_sh_fn
    # Outputs:
    #   {db_prefix}.rdb

    helper_load_config ${params_config_sh_fn}

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.build_contig_db.seqdb.memtime \
    pancake seqdb --block-size ${block_size} ${seqdb_opt} ${params_db_prefix} ${input_p_ctg_fasta} ${input_a_ctg_fasta}

    # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.build_contig_db.seeddb.memtime \
    /usr/bin/time pancake seeddb ${seeddb_opt} ${params_db_prefix}.seqdb ${params_db_prefix}
}

function map_all_prepare {
    # Input:
    #   input_db
    # Output:
    #   *.txt in cwd
    #   ${output_blocks} (same info in 1 file)

    num_blocks=$(awk '/^B/{count++}END{print count}' "${input_db}")
    for ((block1=0;block1<num_blocks;block1++)); do
        echo $block1 > $block1.txt
        echo ${block1}
    done > ${output_blocks}

    if [[ ! -s ${output_blocks} ]]; then
        echo "0" > ${output_blocks}
    fi
}

function map_all_run {
    # Inputs:
    #   input_target_seqdb
    #   input_query_seqdb
    # Params:
    #   params_query_block_id
    #   params_num_threads
    #   params_config_sh_fn

    helper_load_config ${params_config_sh_fn}

    local local_target_db_prefix=${input_target_seqdb%.*}
    local local_query_db_prefix=${input_query_seqdb%.*}
    local local_last_query_block=$((params_query_block_id + 1))

    local opt_use_seq_ids=""

    num_target_blocks=$(awk '/^B/{count++}END{print count}' "${input_target_seqdb}")
    for ((target_block=0;target_block<num_target_blocks;target_block++)); do
        # /usr/bin/time --format="cmd: %C\\nreal_time: %e s\\nuser_time: %U s\\nsys_time: %S s\\nmax_rss: %M kB\\nexit_status: %x" -o log.map_all_run.pancake.tblock_${target_block}.memtime \
        pancake ovl-hifi --bestn 1 --num-threads ${params_num_threads} --one-hit-per-target ${opt_use_seq_ids} ${ovl_opt_erc} --log-level=INFO ${local_target_db_prefix} ${local_query_db_prefix} ${target_block} ${params_query_block_id} ${local_last_query_block}
    done > mapped.m4
}

function map_all_merge {
    # Explicit inputs:
    #   input_fofn
    # Params:
    #   params_config_sh_fn
    helper_load_config ${params_config_sh_fn}

    # Sanity check.
    cat ${input_fofn}
    while read fn; do
        ls -lH ${fn}
    done < ${input_fofn}

    # Merge.
    cat ${input_fofn} | xargs cat > mapped.merged.m4

    # Get read-to-contig mapping.
    cut -d' ' -f1-2 mapped.merged.m4 > read_to_contig.csv
}

function polish_prepare {
    # Input:
    #   input_read_to_contig
    # Output:
    #   *.txt in cwd
    #   ${output_blocks} (same info in 1 file)

    sort -k2,2 ${input_read_to_contig} > sorted.read_to_contig.csv
    awk 'BEGIN { prev = ""; count = 0} { if ($2 != prev) { fn_reads = "block_id."count".reads"; fn_ctg =  "block_id."count".ctg_id"; print $2 > fn_ctg; count++} {print $1 > fn_reads} prev = $2; }' sorted.read_to_contig.csv
}

function polish_run {
    # Inputs:
    #   input_fofn
    #   input_p_ctg_fasta
    #   input_a_ctg_fasta
    # Output:
    #   output_consensus_fn
    # Params:
    #   params_reads_to_contig_fn
    #   params_ctg_id_fn
    #   params_block_id
    #   params_num_threads
    #   params_config_sh_fn

    helper_load_config ${params_config_sh_fn}

    # Extract the contig sequence.
    # The a_ctg.fasta file can be empty, in which case the .fai file does not exist
    draft_fn="draft.fasta"
    samtools faidx ${input_p_ctg_fasta} -r ${params_ctg_id_fn} --continue > ${draft_fn}
    if [[ -s ${input_a_ctg_fasta}.fai ]]; then
        samtools faidx ${input_a_ctg_fasta} -r ${params_ctg_id_fn} --continue >> ${draft_fn}
    fi

    ###########################################################
    ### This handles both .fasta(.gz) and .fastq(.gz) inputs. ###
    ### It ensures that all reads are in the same format.   ###
    ###########################################################
    for fn in $(cat ${input_fofn})
    do
        # Remove the tailing .gz if it's there, and get the extension.
        # local fn_ext=$(echo ${fn} | sed -E 's/^(.*)\.gz$/\1/g' | tr . \\n | tail -n 1)
        echo ${fn} | sed -E 's/^(.*)\.gz$/\1/g' | tr . \\n | tail -n 1
    done > extensions.txt
    sort extensions.txt | uniq -c > extensions.uniq.txt
    # Get the total number of different extensions. Awk is here just to enable portability (wc is different on Mac and Linux).
    local num_ext=$(wc -l extensions.uniq.txt | awk '{ print $1 }')
    if [[ ${num_ext} -ne 1 ]]; then
        echo "All input reads files must be in the same format.!"
        return 1
    fi
    local actual_ext=$(head -n 1 extensions.uniq.txt | awk '{ e = tolower($2); if (e == "fasta" || e == "fa") { print "fasta"} else if (e == "fastq" || e == "fq") { print "fastq"} else { print "unknown" } }')
    ###########################################################

    # Extract the reads. It depends if the input is in FASTA or FASTQ, because
    # of Samtools' faidx and fqidx.
    if [[ ${actual_ext} = "fasta" ]]; then
        # Use the "faidx" tool.
        reads_fn="reads.fasta"
        for fn in $(cat ${input_fofn})
        do
            samtools faidx ${fn} -r ${params_reads_to_contig_fn} --continue
        done > ${reads_fn}
    elif [[ ${actual_ext} = "fastq" ]]; then
        # Use the "fqidx" tool.
        reads_fn="reads.fastq"
        for fn in $(cat ${input_fofn})
        do
            samtools fqidx ${fn} -r ${params_reads_to_contig_fn} --continue
        done > ${reads_fn}
    else
        echo "Unknown extension of one or more of the input files."
        return 1
    fi

    # Map and filter.
    time pbmm2 align --sort -j ${params_num_threads} --preset CCS ${draft_fn} ${reads_fn} | samtools view -q 5 -bh > aln.unfiltered.bam
    time falconc bam-filter-clipped -t -F 0x704 --input-fn:- --output-fn aln.sam --output-count-fn filtered_aln_count.txt < aln.unfiltered.bam

    # The filtered_aln_count.txt is generated by `falconc bam-filter-clipped`.
    local is_good=$(cat filtered_aln_count.txt)
    if [ ${is_good} -eq "0" ]; then
        # There are no records in the SAM file. Create an empty output file.
        touch ${output_consensus_fn}
    else
        time racon -t ${params_num_threads} ${reads_fn} aln.sam ${draft_fn} > ${output_consensus_fn}
    fi

    # Cleanup
    rm -f *.bam *.sam *.fastq
}

function polish_merge {
    # Explicit inputs:
    #   input_fofn
    # Params:
    #   params_config_sh_fn
    helper_load_config ${params_config_sh_fn}

    # Sanity check.
    cat ${input_fofn}
    while read fn; do
        ls -lH ${fn}
    done < ${input_fofn}

    # Merge.
    cat ${input_fofn} | xargs cat > consensus.merged.fasta
}

function help {
    # These can be run from any workflow engine.
    # We call them from both snakemake and cromwell.

    echo "For any subcommand, pass arguments by name in the environment."
    # (The list of subcommands is on the case statement below.)
}

# First, try any non-task commands.
case $1 in
  rm_las \
  |help)
    set -eu -o pipefail
    $*
    exit 0
    ;;
esac

# For a task, print the environment.
env | sort >&2

case $1 in
  which \
  |generate_config_ccs \
  |build_db \
  |ovl_prepare \
  |ovl_asym_run \
  |ovl_asym_merge \
  |ovl_filter \
  |phasing_prepare \
  |phasing_run \
  |phasing_merge \
  |assemble \
  |get_gfa \
  |build_contig_db \
  |map_all_prepare \
  |map_all_merge \
  |map_all_run \
  |polish_prepare \
  |polish_run \
  |polish_merge \
)
    set -vexu -o pipefail
    $*
    ;;
*)
    echo "Bad sub-command for '$0 $@'"
    exit 1
    ;;
esac
